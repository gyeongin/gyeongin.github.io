---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

I am a PhD student at Seoul National University (SNU), advised by [Prof. Byung-Gon Chun](https://bgchun.github.io). My research interest lies in the intersection of computer systems and machine learning, with a focus on systems for machine learning. More specifically, I am primarily working on software techniques to improve machine learning in the datacenter, including both inference and training. 

I received my Bachelor's degree in computer science and engineering (CSE) and economics from SNU in 2017.

Selected Publications
======
You can find my Google Scholar information [here](https://scholar.google.com/citations?user=RwhPHaEAAAAJ).

1. **Gyeong-In Yu**, Saeed Amizadeh, Sehoon Kim, Artidoro Pagnoni, Ce Zhang, Byung-Gon Chun, Markus Weimer, Matteo Interlandi. WindTunnel: Towards Differentiable ML Pipelines Beyond a Single Model. To appear in _48th International Conference on Very Large Data Bases (VLDB 2022)_. [\[paper\]](http://vldb.org/pvldb/vol15/p11-yu.pdf)
1. Taebum Kim, Eunji Jeong, Geon-Woo Kim, Yunmo Koo, Sehoon Kim, **Gyeong-In Yu**, Byung-Gon Chun. Terra: Imperative-Symbolic Co-Execution of Imperative Deep Learning Programs. _35th Conference on Neural Information Processing Systems (NeurIPS 2021)_, December 2021. [\[paper\]](https://proceedings.neurips.cc/paper/2021/hash/0b32f1a9efe5edf3dd2f38b0c0052bfe-Abstract.html)
1. Woosuk Kwon\*, **Gyeong-In Yu\***, Eunji Jeong, Byung-Gon Chun (**\*equal contribution**). Nimble: Lightweight and Efficient GPU Task Scheduling for Deep Learning. _34th Conference on Neural Information Processing Systems (NeurIPS 2020) (Spotlight)_, December 2020. [\[paper\]](https://proceedings.neurips.cc/paper/2020/hash/5f0ad4db43d8723d18169b2e4817a160-Abstract.html)
1. Supun Nakandala, Karla Saur, **Gyeong-In Yu**, Konstantinos Karanasos, Carlo Curino, Markus Weimer, Matteo Interlandi. A Tensor Compiler Approach for One-size-fits-all ML Prediction Serving. _14th USENIX Symposium on Operating Systems Design and Implementation (OSDI 2020)_, November 2020. [\[paper\]](https://www.usenix.org/conference/osdi20/presentation/nakandala)
1. Woo-Yeon Lee, Yunseong Lee, Joo Seong Jeong, **Gyeong-In Yu**, Joo Yeon Kim, Ho Jin Park, Beomyeol Jeon, Wonwook Song, Gunhee Kim, Markus Weimer, Brian Cho, Byung-Gon Chun. Automating System Configuration of Distributed Machine Learning. _39th IEEE International Conference on Distributed Computing Systems (ICDCS 2019)_, July 2019. [\[paper\]](https://conferences.computer.org/icdcs/2019/pdfs/ICDCS2019-49XpIlu3rRtYi2T0qVYnNX/1yYnh1qhs5eJA4Iw4FM6Go/mAFPBWg4OOIB3xAPzJvzu.pdf)
1. Soojeong Kim, **Gyeong-In Yu**, Hojin Park, Sungwoo Cho, Eunji Jeong, Hyeonmin Ha, Sanha Lee, Joo Seong Jeong, Byung-Gon Chun. Parallax: Sparsity-aware Data Parallel Training of Deep Neural Networks. _14th European Conference on Computer Systems (EuroSys 2019)_, March 2019. [\[paper\]](https://dl.acm.org/doi/10.1145/3302424.3303957)
1. Eunji Jeong, Sungwoo Cho, **Gyeong-In Yu**, Joo Seong Jeong, Dongjin Shin, Byung-Gon Chun. JANUS: Fast and Flexible Deep Learning via Symbolic Graph Execution of Imperative Programs. _16th USENIX Symposium on Networked Systems Design and Implementation (NSDI 2019)_, February 2019. [\[paper\]](https://www.usenix.org/conference/nsdi19/presentation/jeong)
1. **Gyeong-In Yu**, Saeed Amizadeh, Byung-Gon Chun, Markus Weimer, Matteo Interlandi. Making Classical Machine Learning Pipelines Differentiable: A Neural Translation Approach. _Systems for ML Workshop at 32nd Conference on Neural Information Processing Systems (NeurIPS)_, December 2018. [\[paper\]](http://learningsys.org/nips18/assets/papers/45CameraReadySubmissionfinetune.pdf)
1. Eunji Jeong\*, Joo Seong Jeong\*, Soojeong Kim, **Gyeong-In Yu**, Byung-Gon Chun (\*equal contribution). Improving the Expressiveness of Deep Learning Frameworks with Recursion. _13th European Conference on Computer Systems (EuroSys 2018)_, April 2018. [\[paper\]](https://dl.acm.org/doi/10.1145/3190508.3190530)
